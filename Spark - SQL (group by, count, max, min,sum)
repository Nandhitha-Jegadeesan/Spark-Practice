from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("PracticeData").getOrCreate()

employees_data = [
    (1, "Alice", "HR", 50000),
    (2, "Bob", "Finance", 70000),
    (3, "Charlie", "HR", 55000),
    (4, "David", "IT", 60000),
    (5, "Eva", "Finance", 75000),
    (6, "Frank", "IT", 65000)
]

employees_columns = ["emp_id", "name", "department", "salary"]
employees_df = spark.createDataFrame(employees_data, employees_columns)
employees_df.show()


orders_data = [
    (101, "C1", 250, 3, "North"),
    (102, "C2", 300, 4, "South"),
    (103, "C1", 450, 2, "North"),
    (104, "C3", 500, 1, "West"),
    (105, "C2", 150, 3, "South"),
    (106, "C3", 400, 2, "West")
]

orders_columns = ["order_id", "customer_id", "order_amount","quantity_sold", "region"]
orders_df = spark.createDataFrame(orders_data, orders_columns)
orders_df.show()

products_data = [
    ("P1", "Phone", "Electronics", 600, "VendorA"),
    ("P2", "Laptop", "Electronics", 1200, "VendorB"),
    ("P3", "Rice", "Grocery", 50, "VendorC"),
    ("P4", "Oil", "Grocery", 80, "VendorC"),
    ("P5", "Headphones", "Electronics", 200, "VendorA")
]

products_columns = ["product_id", "name", "category", "price", "vendor"]
products_df = spark.createDataFrame(products_data, products_columns)
products_df.show()


reviews_data = [
    ("R1", "P1", "C1", 4),
    ("R2", "P1", "C2", 5),
    ("R3", "P2", "C3", 3),
    ("R4", "P3", "C2", 4),
    ("R5", "P4", "C1", 2),
    ("R6", "P2", "C1", 4)
]

reviews_columns = ["review_id", "product_id", "customer_id", "rating"]
reviews_df = spark.createDataFrame(reviews_data, reviews_columns)
reviews_df.show()


# Registering temporary views for SQL usage
orders_df.createOrReplaceTempView("orders")
employees_df.createOrReplaceTempView("emp")
products_df.createOrReplaceTempView("product")
reviews_df.createOrReplaceTempView("review")

# Q1: Total number of orders placed by each customer
spark.sql("""
    SELECT customer_id, COUNT(*) AS total_orders
    FROM orders
    GROUP BY customer_id
""").show()

# Q2: Average salary of employees
spark.sql("""
    SELECT AVG(salary) AS average_salary
    FROM emp
""").show()

# Q3: Min and Max product price grouped by category
spark.sql("""
    SELECT category, MIN(price) AS minimum, MAX(price) AS maximum
    FROM product
    GROUP BY category
""").show()

# Q4: Count of employees
spark.sql("""
    SELECT COUNT(emp_id) AS no_of_employees
    FROM emp
""").show()

# Q5: Total revenue per product name
spark.sql("""
    SELECT name, SUM(price) AS revenues
    FROM product
    GROUP BY name
""").show()

# Q6: Maximum salary in each department
spark.sql("""
    SELECT department, MAX(salary) AS highest_salary
    FROM emp
    GROUP BY department
""").show()

# Q7: Average rating per product
spark.sql("""
    SELECT product_id, AVG(rating) AS avg_rating
    FROM review
    GROUP BY product_id
""").show()

# Q8: Total sales per region
spark.sql("""
    SELECT region, SUM(order_amount) AS total_sales
    FROM orders
    GROUP BY region
""").show()

# Q9: Max and Min quantity sold per product
spark.sql("""
    SELECT product_id, MAX(quantity_sold) AS highest, MIN(quantity_sold) AS lowest
    FROM orders
    GROUP BY product_id
""").show()

# Q10: Count of products supplied by each vendor
spark.sql("""
    SELECT vendor, COUNT(name) AS product_count
    FROM product
    GROUP BY vendor
""").show()
